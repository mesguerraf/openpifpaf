{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Sven Kreiss](https://www.svenkreiss.com/), 2020\n",
    "\n",
    "# Datasets\n",
    "\n",
    "This section describes how to install common datasets used for training new models and for computing evaluation scores for entire datasets. In general, these datasets are large and require a computer with a good GPU to train and evaluate in reasonable times.\n",
    "\n",
    "These datasets are not required to do pose predictions on your own images.\n",
    "\n",
    "You are unlikely to need all the datasets, so donwload only what you need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download COCO data\n",
    "\n",
    "[COCO](http://cocodataset.org/) is a great datasets containing many types of annotations, including bounding boxes, 2D poses, etc.\n",
    "\n",
    "```sh\n",
    "mkdir data-mscoco\n",
    "cd data-mscoco\n",
    "gsutil ls gs://images.cocodataset.org  # to list available directories\n",
    "\n",
    "mkdir -p images/val2017\n",
    "gsutil -m rsync gs://images.cocodataset.org/val2017 images/val2017\n",
    "\n",
    "mkdir -p images/train2017\n",
    "gsutil -m rsync gs://images.cocodataset.org/train2017 images/train2017\n",
    "\n",
    "gsutil cp gs://images.cocodataset.org/annotations/annotations_trainval2017.zip .\n",
    "# or\n",
    "wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip\n",
    "unzip annotations_trainval2017.zip\n",
    "wget http://images.cocodataset.org/annotations/image_info_test2017.zip\n",
    "unzip image_info_test2017.zip\n",
    "\n",
    "# test images: run inside of images directory\n",
    "wget http://images.cocodataset.org/zips/test2017.zip\n",
    "unzip test2017.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Person Skeletons\n",
    "\n",
    "COCO / kinematic tree / dense:\n",
    "\n",
    "```{image} ../docs/skeleton_coco.png\n",
    ":height: \"250\"\n",
    "```\n",
    "```{image} ../docs/skeleton_kinematic_tree.png\n",
    ":height: \"250\"\n",
    "```\n",
    "```{image} ../docs/skeleton_dense.png\n",
    ":height: \"250\"\n",
    "```\n",
    "\n",
    "Created with `python3 -m openpifpaf.datasets.constants`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(coco-person-keypoints)=\n",
    "## COCO Person Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 nose\n",
      "1 left_eye\n",
      "2 right_eye\n",
      "3 left_ear\n",
      "4 right_ear\n",
      "5 left_shoulder\n",
      "6 right_shoulder\n",
      "7 left_elbow\n",
      "8 right_elbow\n",
      "9 left_wrist\n",
      "10 right_wrist\n",
      "11 left_hip\n",
      "12 right_hip\n",
      "13 left_knee\n",
      "14 right_knee\n",
      "15 left_ankle\n",
      "16 right_ankle\n"
     ]
    }
   ],
   "source": [
    "import openpifpaf\n",
    "for i, name in enumerate(openpifpaf.datasets.constants.COCO_KEYPOINTS):\n",
    "    print(i, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "associations\n",
      " 0: left_ankle      --> left_knee\n",
      " 1: left_knee       --> left_hip\n",
      " 2: right_ankle     --> right_knee\n",
      " 3: right_knee      --> right_hip\n",
      " 4: left_hip        --> right_hip\n",
      " 5: left_shoulder   --> left_hip\n",
      " 6: right_shoulder  --> right_hip\n",
      " 7: left_shoulder   --> right_shoulder\n",
      " 8: left_shoulder   --> left_elbow\n",
      " 9: right_shoulder  --> right_elbow\n",
      "10: left_elbow      --> left_wrist\n",
      "11: right_elbow     --> right_wrist\n",
      "12: left_eye        --> right_eye\n",
      "13: nose            --> left_eye\n",
      "14: nose            --> right_eye\n",
      "15: left_eye        --> left_ear\n",
      "16: right_eye       --> right_ear\n",
      "17: left_ear        --> left_shoulder\n",
      "18: right_ear       --> right_shoulder\n"
     ]
    }
   ],
   "source": [
    "print('associations')\n",
    "kp_names = openpifpaf.datasets.constants.COCO_KEYPOINTS\n",
    "for i, (joint1, joint2) in enumerate(openpifpaf.datasets.constants.COCO_PERSON_SKELETON):\n",
    "    print('{:2d}: {:15s} --> {}'.format(i, kp_names[joint1 - 1], kp_names[joint2 - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download MPII data\n",
    "\n",
    "This MPII data is currently not used anywhere.\n",
    "\n",
    "```sh\n",
    "mkdir data-mpii\n",
    "cd data-mpii\n",
    "wget https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1.tar.gz\n",
    "wget https://datasets.d2.mpi-inf.mpg.de/andriluka14cvpr/mpii_human_pose_v1_u12_2.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download NightOwls data\n",
    "\n",
    "```sh\n",
    "mkdir data-nightowls\n",
    "cd data-nightowls\n",
    "wget http://www.robots.ox.ac.uk/\\~vgg/data/nightowls/python/nightowls_validation.json\n",
    "wget http://www.robots.ox.ac.uk/\\~vgg/data/nightowls/python/nightowls_validation.zip\n",
    "unzip nightowls_validation.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
